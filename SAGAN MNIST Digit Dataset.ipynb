{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29145bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Utility function to use GPU if exist\n",
    "def cuda(data):\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Utility function for help of arranging sample images\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n",
    "  \n",
    "# Fix a random latent input for samples\n",
    "fixed_z = cuda(torch.randn(64, 100))\n",
    "batch_size = 64\n",
    "\n",
    "# Define data transformer\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Read data and transform\n",
    "dataset = MNIST(root='./data', download=True, train=True, transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a460ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Construct the conv layers\n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        \n",
    "        # Initialize gamma as 0\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B * C * W * H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B * N * N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        \n",
    "        proj_query  = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0,2,1) # B * N * C\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        energy =  torch.bmm(proj_query, proj_key) # batch matrix-matrix product\n",
    "        \n",
    "        attention = self.softmax(energy) # B * N * N\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        out = torch.bmm(proj_value, attention.permute(0,2,1)) # batch matrix-matrix product\n",
    "        out = out.view(m_batchsize,C,width,height) # B * C * W * H\n",
    "        \n",
    "        # Add attention weights onto input\n",
    "        out = self.gamma*out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6642bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spectral import SpectralNorm\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator\n",
    "    input: \n",
    "        z: latent matrix with shape of (batch_size, 100)\n",
    "    output: \n",
    "        out: generated image with shape (batch_size, 1, 28, 28)\n",
    "        p1: attention matrix generated by attn layer\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=64, attn=True, image_size=28, z_dim=100, conv_dim=64):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        \n",
    "        # Layer 1 turn 100 dims -> 512 dims, size 1 -> 3\n",
    "        layer1 = []\n",
    "        layer1.append(SpectralNorm(nn.ConvTranspose2d(in_channels = z_dim, out_channels = conv_dim*8, kernel_size = 3)))\n",
    "        layer1.append(nn.BatchNorm2d(conv_dim*8))\n",
    "        layer1.append(nn.ReLU())\n",
    "        self.l1 = nn.Sequential(*layer1)\n",
    "        \n",
    "        # Layer 2 turn 512 dims -> 256 dims, size 3 -> 7\n",
    "        layer2 = []\n",
    "        layer2.append(SpectralNorm(nn.ConvTranspose2d(in_channels = conv_dim*8, out_channels = conv_dim*4, \n",
    "                                                      kernel_size = 3, stride = 2, padding = 0)))\n",
    "        layer2.append(nn.BatchNorm2d(conv_dim*4))\n",
    "        layer2.append(nn.ReLU())\n",
    "        self.l2 = nn.Sequential(*layer2)\n",
    "        \n",
    "        # Layer 3 turn 256 dims -> 128 dims, size 7 -> 14\n",
    "        layer3 = []\n",
    "        layer3.append(SpectralNorm(nn.ConvTranspose2d(in_channels = conv_dim*4, out_channels = conv_dim*2, \n",
    "                                                      kernel_size = 4, stride = 2, padding = 1)))\n",
    "        layer3.append(nn.BatchNorm2d(conv_dim*2))\n",
    "        layer3.append(nn.ReLU())\n",
    "        self.l3 = nn.Sequential(*layer3)\n",
    "\n",
    "        # Layer 4 (Attn) turn 128 dims -> 128 dims\n",
    "        self.attn = Self_Attn(conv_dim*2)\n",
    "        \n",
    "        # Layer 5 turn 128 dims -> 1 dims, size 14 -> 28\n",
    "        last = []\n",
    "        last.append(nn.ConvTranspose2d(conv_dim*2, 1, 4, 2, 1))\n",
    "        last.append(nn.Tanh())\n",
    "        self.last = nn.Sequential(*last)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z is the input random matrix for generator\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        out=self.l1(z)\n",
    "        out=self.l2(out)\n",
    "        out=self.l3(out)\n",
    "        if self.attn == True:\n",
    "            out = self.attn(out)\n",
    "        out=self.last(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator\n",
    "    input:\n",
    "        x: one batch of data with shape of (batch_size, 1, 28, 28)\n",
    "    output: \n",
    "        out.squeeze: a batch of scalars indicating the predict results\n",
    "        p1: attention matrix generated by attn layer\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=64, attn=True, image_size=28, conv_dim=64):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        \n",
    "        layer1 = []\n",
    "        layer1.append(SpectralNorm(nn.Conv2d(1, conv_dim, 4, 2, 1)))\n",
    "        layer1.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = conv_dim\n",
    "        self.l1 = nn.Sequential(*layer1)\n",
    "        \n",
    "        layer2 = []\n",
    "        layer2.append(SpectralNorm(nn.Conv2d(curr_dim, curr_dim * 2, 4, 2, 1)))\n",
    "        layer2.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = curr_dim * 2\n",
    "        self.l2 = nn.Sequential(*layer2)\n",
    "        \n",
    "        layer3 = []\n",
    "        layer3.append(SpectralNorm(nn.Conv2d(curr_dim, curr_dim * 2, 4, 2, 1)))\n",
    "        layer3.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = curr_dim * 2\n",
    "        self.l3 = nn.Sequential(*layer3)\n",
    "        \n",
    "        self.attn = Self_Attn(curr_dim)\n",
    "        \n",
    "        last = []\n",
    "        last.append(nn.Conv2d(curr_dim, 1, 4, 2, 1))\n",
    "        self.last = nn.Sequential(*last)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        if self.attn == True:\n",
    "            out = self.attn(out)\n",
    "        out=self.last(out)\n",
    "\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c891363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "def train(steps = 100000, batch_size = 64, z_dim = 100, attn = True):\n",
    "    # Initialize model\n",
    "    G = cuda(Generator(batch_size, attn))\n",
    "    D = cuda(Discriminator(batch_size, attn))\n",
    "    \n",
    "    # Make directory for samples and models\n",
    "    cwd = os.getcwd()\n",
    "    post='_attn' if attn else ''\n",
    "    if not os.path.exists(cwd+'/samples_mnist'+post):\n",
    "        os.makedirs(cwd+'/samples_mnist'+post)\n",
    "\n",
    "    # Initialize optimizer with filter, lr and coefficients\n",
    "    g_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, G.parameters()), 0.0001, [0.0,0.9])\n",
    "    d_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, D.parameters()), 0.0004, [0.0,0.9])\n",
    "    \n",
    "    # Load a batch of data\n",
    "    Iter = iter(dataloader)\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # ================== Train D ================== #\n",
    "        D.train(); G.train()\n",
    "        try:\n",
    "            real_images,_ = next(Iter)\n",
    "        except:\n",
    "            Iter = iter(dataloader)\n",
    "            real_images,_ = next(Iter)\n",
    "        \n",
    "        # Compute loss with real images\n",
    "        d_out_real = D(cuda(real_images))\n",
    "        d_loss_real = torch.nn.ReLU()(1.0 - d_out_real).mean()\n",
    "        \n",
    "        # Compute loss with fake images\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        d_out_fake = D(fake_images)\n",
    "        d_loss_fake = torch.nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "        \n",
    "        # Backward + Optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================== Train G ================== #\n",
    "        # Create random noise\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        g_out_fake = D(fake_images)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        g_loss_fake.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Print out log info\n",
    "        if (step + 1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            expect = elapsed/(step + 1)*(steps-step-1)\n",
    "            elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "            expect = str(datetime.timedelta(seconds=expect))\n",
    "            clear_output(wait=True)\n",
    "            print(\"Elapsed [{}], Expect [{}], step [{}/{}], D_real_loss: {:.4f}, \"\n",
    "                  \" ave_generator_gamma: {:.4f}\".\n",
    "                  format(elapsed,expect,step + 1,steps,d_loss_real.item(),G.attn.gamma.mean().item()))\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Sample images\n",
    "        if (step + 1) % (100) == 0:\n",
    "            fake_images= G(fixed_z)\n",
    "            save_image(denorm(fake_images), os.path.join('./samples_mnist'+post, '{}_fake.png'.format(step + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63692a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(steps = 60000, attn = False)\n",
    "print('Done training part 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b792a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"./demo/arial.ttf\", 18)\n",
    "def create_image_with_text(img, wh, text):\n",
    "    width, height = wh\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((width, height), text, font = font, fill=\"white\")\n",
    "    return img\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(100, 20001, 100):\n",
    "    img = Image.open('samples_mnist/{}_fake.png'.format(str(i)))\n",
    "    img1 = Image.open('samples_mnist_attn/{}_fake.png'.format(str(i)))\n",
    "    width, height = img.size\n",
    "    expand = Image.new(img.mode, (width*2 + 10, height + 40), \"black\")\n",
    "    expand.paste(img, (0, 0))\n",
    "    expand.paste(img1, (width + 10, 0))\n",
    "    epoch = round(i*64/60000,2)\n",
    "    new_frame = create_image_with_text(expand,(10,258), \"After \"+str(epoch)+\" epoches\")\n",
    "    new_frame = create_image_with_text(new_frame,(10,238), \"Without Attention\")\n",
    "    new_frame = create_image_with_text(new_frame,(width + 20,238), \"With Attention\")\n",
    "    frames.append(new_frame)\n",
    "    \n",
    "frames[0].save('./demo/comparison_mnist.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=60, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
